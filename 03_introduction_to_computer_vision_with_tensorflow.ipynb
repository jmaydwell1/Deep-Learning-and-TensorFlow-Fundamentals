{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-introduction-to-computer-vision-with-tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMSRJ+818bmqNWgYRJiWXxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmaydwell1/Tensorflow-Deep-Learning/blob/main/03_introduction_to_computer_vision_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Convulutional Neural Networks and Computer Visson with TensorFlow\n",
        "\n",
        "Computer vision is the practice of writing algorithms which can discover patterns in visual data. Such as the camera of a self-driving car recognizing the car in front"
      ],
      "metadata": {
        "id": "PIhUCbW3qDcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "The images we're working with are from the Food1001 dataset (101 different classes of food): https://www.kaggle.com/dansbecker/food-101\n",
        "\n",
        "However we've modified it to only use two classes (pizza & steak) using the image data modification notebook.\n",
        "\n",
        "**Note:** We start with a smaller dataset so we can experiment quickly and figure what works (or better yet what doesn't work) before scaling up.\n"
      ],
      "metadata": {
        "id": "0zgb4UhzuEHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "XsNhAQ5NuGxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the data (become one with it)\n",
        "\n",
        "A very crucial step at the beginning of any machine learning project is becoming one iwth the data.\n",
        "\n",
        "And for a computer vision project... this usually means visualizing many samples of your data."
      ],
      "metadata": {
        "id": "pCJPbnjTuzOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak "
      ],
      "metadata": {
        "id": "cgmS_bwRwXLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train/"
      ],
      "metadata": {
        "id": "amiieEAewf5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train/steak"
      ],
      "metadata": {
        "id": "Qu1YKKf1wjsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\" )\n",
        "  "
      ],
      "metadata": {
        "id": "Ooj9lQL6wnoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The extra file in our pizza_steak directory is \".DS_Store\"\n",
        "!ls -la pizza_steak"
      ],
      "metadata": {
        "id": "a33NdqURxaK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to find out how many images are in a file\n",
        "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "\n",
        "num_steak_images_train"
      ],
      "metadata": {
        "id": "r3lOx9C_xdgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize our images, first let's get the class names programmatically"
      ],
      "metadata": {
        "id": "mUiEaQSmyVjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the classnames programmatically\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(\"pizza_steak/train\")\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # Created a list of class_names from the sbudirectories \n",
        "class_names = class_names[1:]\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "iKs6ba_WyTRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize our images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  # Setup the target directory (we'll view images from here)\n",
        "  target_folder = target_dir+target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "  print(random_image)\n",
        "\n",
        "  # Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # Show the shape of the image\n",
        "\n",
        "  return img\n"
      ],
      "metadata": {
        "id": "TdYKSruWzVWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random image form the trainng dataset\n",
        "img = view_random_image(target_dir=\"pizza_steak/train/\",\n",
        "                        target_class=\"pizza\")"
      ],
      "metadata": {
        "id": "aaM99NGA0lPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.constant(img)"
      ],
      "metadata": {
        "id": "AiR57jcH06Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the image shape\n",
        "img.shape # returns width, height, colo samples "
      ],
      "metadata": {
        "id": "N-4niGdZ1veb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** As we've discussed before, mancy machine learning models, including neural networks prefer the values they work with to be between 0 and 1. Knowing this, one of the most common preprocessing steps for working with images is to scale (also referred to as normalize) their pixel values by dividing the image arrays by 255. (since 255 is the maximum pixel value)."
      ],
      "metadata": {
        "id": "c4tqMRni27El"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the pixel values between 0 & 1\n",
        "img/255."
      ],
      "metadata": {
        "id": "D4ZGufDP2dxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An end-to-end example\n",
        "\n",
        "Let's build a convolutional neural network to find patterns in our images, more specifically we need a way to:\n",
        "\n",
        "* Load our image\n",
        "* Preprocess our image\n",
        "* Build a CNN to find patterns in our images\n",
        "* Compile our CNN\n",
        "* Fit the CNN to our training data"
      ],
      "metadata": {
        "id": "IXdgIfxA2m3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocessing data (get all of the pixel values between 0 & 1, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup paths to our data directories\n",
        "train_dir = \"/content/pizza_steak/train\"\n",
        "test_dir = \"pizza_steak/test\"\n",
        "\n",
        "# Import data from directorie and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                              batch_size=32,\n",
        "                                              target_size=(224, 224),\n",
        "                                              class_mode=\"binary\",\n",
        "                                              seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(directory=test_dir,\n",
        "                                                batch_size=32,\n",
        "                                                target_size=(224, 224),\n",
        "                                                class_mode=\"binary\",\n",
        "                                                seed=42)\n",
        "\n",
        "# Build a CNN model (same as the Tiny VGG on the CNN explaiiner website)\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=3,\n",
        "                           activation=\"relu\",\n",
        "                           input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                              padding=\"valid\"),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile our CNN\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "9B780XC581ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** If the aboce cell is taking longer than  10 seconds per epoch, make sure you're using a GPU by going to Runtime->Hardware Accelator-> GPU (you may have to rerun some cells above)."
      ],
      "metadata": {
        "id": "an-_00DqRr0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "NZBdNy-gCOBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1500/32"
      ],
      "metadata": {
        "id": "mQi0ZbNRCPcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "nJYN3W0mCS5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the same model as before\n",
        "\n",
        "Let's replicate the model we've built in a previous section to see if it works with our image data.\n",
        "\n",
        "The model we're building is from the TensorFlowplayground"
      ],
      "metadata": {
        "id": "u1hck0qYScpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model to replicate the TensorFlow Playground model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_2 = model_2.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "1houOJ4ZTVkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of model_2\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "SHtRw2GGXsX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite having 20x more parameters than our CNN (model_1),\n",
        "model_2 perfomr terribly... lets try to improve it."
      ],
      "metadata": {
        "id": "GFqY7NkcX2ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model(same as above but let's step it up a notch)\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model \n",
        "history_3 = model_3.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "WSpbrrU1XxSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get summary of model_3\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "YO-xO9RQ5MWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification: Let's break it down\n",
        "\n",
        "1. Become one with the data (visualize, visualize, visualize)\n",
        "2. Preprocess the dat (repared it four our model, the main step here was scaling/normalizing & turning our data into batches)\n",
        "3. Created a model (start with a baseline)\n",
        "4. Fit the model\n",
        "5. Evaluate the model\n",
        "6. Adjust different parameters and improve the model (try to beat our baseline)\n",
        "7. Repeat until satisfied (experiment, exoeriment, experiment)"
      ],
      "metadata": {
        "id": "oXu2I9m97Sd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Become one with the data"
      ],
      "metadata": {
        "id": "cIW8Oyn18TtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "plt.figure()\n",
        "plt.subplot(1, 2, 1)\n",
        "steak_img = view_random_image(\"pizza_steak/train/\", \"steak\")\n",
        "plt.subplot(1, 2, 2)\n",
        "pizza_img = view_random_image(\"pizza_steak/train/\", \"pizza\")"
      ],
      "metadata": {
        "id": "HBmLCA2W7_aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess the data (prepare it for a model)"
      ],
      "metadata": {
        "id": "XYGEnjTe8698"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define direcotyr dataset paths\n",
        "train_dir = \"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\""
      ],
      "metadata": {
        "id": "gT2lAmdi9s7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next step is to turn our data into **batches**.\n",
        "\n",
        "A batch is a small subset of data. Rather than look at all 10,000 images at one time, a model might only look at 32 at a time. \n",
        "\n",
        "It does this for a couple of reason:\n",
        "  1. 10,000 images (or more) might not fit into the memory of your processor (GPU)\n",
        "  2. Trying to learn the patterns in 10,000 images in one hit could result in the model not being able to learn very well.\n",
        "\n",
        "Why 32?\n",
        "Because 32 is good for your health... "
      ],
      "metadata": {
        "id": "rj1rOl4w95es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test data generators and rescale the data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ],
      "metadata": {
        "id": "hBb2l9uf93s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our image data from directories and turn them into batches\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               batch_size=32)\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                            target_size=(224, 224),\n",
        "                                            class_mode=\"binary\",\n",
        "                                            batch_size=32)"
      ],
      "metadata": {
        "id": "l6bNPEhH-gZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a sample of a train data batch\n",
        "images, labels = train_data.next() # get the 'next' batch of images/labels in train_data\n",
        "len(images), len(labels)"
      ],
      "metadata": {
        "id": "PJt0DzgxBYOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many batches are there?\n",
        "1500/32"
      ],
      "metadata": {
        "id": "z1I1--V1CJS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first two images\n",
        "images[:2], images[0].shape"
      ],
      "metadata": {
        "id": "c0SI_cX8CQP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the first batch of labels\n",
        "labels"
      ],
      "metadata": {
        "id": "ePe5sW2ZCYUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a CNN model (start with a baseline)\n",
        "A baseline is a relatively simple model or existing result that you setup when beginning a machine learning experiment and then as you keep experimenting, you try to beat the baseline.\n",
        "\n",
        "**Note:** In deep learning, there is almost an infinite amount of architectures you could create. So one of the best ways to get started is to start with something simple and seeif it works on your data and then introduce complexity as required (e.g. look at which current model is perfomring best in the field for your problemF)."
      ],
      "metadata": {
        "id": "RONQ7I_QCr_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the creating off our model a little easier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "FZmmsXQpDXJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this will be our baseline, a layer convolutional neural network)\n",
        "model_4 = Sequential([\n",
        "    Conv2D(filters=10,\n",
        "           kernel_size=3,\n",
        "           strides=1,\n",
        "           padding=\"valid\",\n",
        "           activation=\"relu\",\n",
        "           input_shape=(224, 224, 3)), # input layer (specify input shape)\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\") # outputlayer (working with binary classification so only 1 output neuron)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "4pTdOCR-DzPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "uD6we_JzIdah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Fit the model"
      ],
      "metadata": {
        "id": "Co-B6TMNI0_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of trainig and test data generators\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "3j8dG3KNI77X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_4 = model_4.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data),\n",
        "                        callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "nq9xYy6AJWHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "id": "aQXal8grJ_dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluating our model\n",
        "It looks like our model is learning something, let's evaluate it."
      ],
      "metadata": {
        "id": "1UvAlvkvShdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the training curves\n",
        "import pandas as pd\n",
        "pd.DataFrame(history_4.history).plot(figsize=(10, 7))"
      ],
      "metadata": {
        "id": "-6SjfysSSxeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training curves separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label=\"training_loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"val_loss\")\n",
        "  plt.title(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.plot(epochs, accuracy, label=\"training_accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
        "  plt.title(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n"
      ],
      "metadata": {
        "id": "vLnwUM2FTLrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** When a model's **validation loss starts to increas**, it's likely that the model is **overfitting** the triaining dataset. This means, it's learning the patterns in the training dataset *too well* and thus the model's ability to generalize to unseen data will be diminished."
      ],
      "metadata": {
        "id": "_qDoiWCWVXRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the loss and accuracy of model_4\n",
        "plot_loss_curves(history_4)"
      ],
      "metadata": {
        "id": "dhkQkvmVUitr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Ideally the two loss curves (trainig and validation) will be very similar to each other decreasing at similar rates), when there are large differnces your model may be overfitting."
      ],
      "metadata": {
        "id": "EQhHDBIqWbt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Adjust the mode parameters\n",
        "\n",
        "Fitting a machine learning model come ins 3 steps:\n",
        "\n",
        "0. Create a baseline\n",
        "1. Beat the baselien by overfitting a larger model\n",
        "2. Reduce overfitting\n",
        "\n",
        "Ways to induce overfitting:\n",
        "* Increase the number of conv layers\n",
        "* Increase the number of conv filters\n",
        "* Add another dense layer to the output of our flattened layer\n",
        "\n",
        "Reduce overfitting:\n",
        "* Add data augmentation\n",
        "* Add regularization layers (such as MaxPool2D)\n",
        "* Add more data... \n",
        "\n",
        "**Note:** Reducing overfitting is also known as **regularization**.\n"
      ],
      "metadata": {
        "id": "gDljShKpWpBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this is going to be our new baseline)\n",
        "model_5 = Sequential([\n",
        "    Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "    MaxPool2D(pool_size=2),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "3MAtiy3AXtmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Prjz-UsDZd6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_5 = model_5.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "5UgJ_jT6ZvHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our model with max pooling \n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "sfnzfOIJaMQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "id": "9p0ETI2JbqBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_5)"
      ],
      "metadata": {
        "id": "1D6zpjiabv2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Opening our bag of tricks and finding data augmentation"
      ],
      "metadata": {
        "id": "N0HV72r5b4Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ImageDataGenerator training instance with data augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=0.2,\n",
        "                                             shear_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.3,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Create ImageDataGenerator without dat augmentation for the test dataset\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n"
      ],
      "metadata": {
        "id": "Pg-GErgLcvH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question** What is data augmentation?\n",
        "\n",
        "Data Augmentation is the process of altering our training data, leaading it to have more diversity and in turn allowing our models to learn more geralizable (hopefully) patterns. Altering might mean adjusting the roataion of an image, flippingit, cropping it or something similar.\n",
        "\n",
        "Let's write some code to visualize data augmentation..."
      ],
      "metadata": {
        "id": "-ok2n2Did-3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dat and augment it from training directory\n",
        "print(\"augmented training data\")\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                   target_size=(224, 224),\n",
        "                                                                   batch_size=32,\n",
        "                                                                   class_mode=\"binary\",\n",
        "                                                                   shuffle=False) # for demonstration purposes only\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "# Created non-augmented test data batches\n",
        "print(\"Non-augmented test data:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             batch_size=32,\n",
        "                                             class_mode=\"binary\")"
      ],
      "metadata": {
        "id": "mR1L4T99daUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Data augmentation is usally only performed on the training data. Using `ImageDataGenerator` built-in data augmentation parameters our images are left as they are in the drectories but are modified as they're loaded into the model.\n",
        "\n",
        "Finaly let's visualize some augmented data!!!"
      ],
      "metadata": {
        "id": "KO1u0OZ_qntT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample data batches\n",
        "images, labels = train_data.next()\n",
        "augmented_images, augmented_labels = train_data_augmented.next()"
      ],
      "metadata": {
        "id": "Uae3jasspjpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show original image and augmented image\n",
        "import random\n",
        "random_number = random.randint(0, 32) # our batch sizes are 32...\n",
        "print(f\"showing image number: {random_number}\")\n",
        "plt.imshow(images[random_number])\n",
        "plt.title(f\"Original image\")\n",
        "plt.axis(False)\n",
        "plt.figure()\n",
        "plt.imshow(augmented_images[random_number])\n",
        "plt.title(f\"Augmented image\")\n",
        "plt.axis(False)\n"
      ],
      "metadata": {
        "id": "yicp2Gl2rfqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've seen what augmented training data looks like, let's build a model and see how it learns on augmented data."
      ],
      "metadata": {
        "id": "fGORmx6hwNIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model (same as model_5)\n",
        "model_6 = Sequential([\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(pool_size=2),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_6 = model_6.fit(train_data_augmented, # Fitting model_6 on augmented training data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "g_Mnk_tEwWBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our models training curves\n",
        "plot_loss_curves(history_6)"
      ],
      "metadata": {
        "id": "kmVsP_MEx5sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's shuffle our augmented training data and train another model (the same as before) on it adn see what happens."
      ],
      "metadata": {
        "id": "uK5d_KHQ3_9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and augment it and shuffle from training directory\n",
        "train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                            target_size=(224, 224),\n",
        "                                                                            class_mode=\"binary\",\n",
        "                                                                            batch_size=32,\n",
        "                                                                            shuffle=True) # shuffle data this time"
      ],
      "metadata": {
        "id": "yPy9txeZ3pbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (same as model_5 and model_6)\n",
        "model_7 = Sequential([\n",
        "    Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "history_7 = model_7.fit(train_data_augmented_shuffled, # We're fitting on augmented and shuffled data now\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented_shuffled),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "JPfAl4l14sXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves \n",
        "plot_loss_curves(history_7)"
      ],
      "metadata": {
        "id": "f40z3BRg8ViF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Repeat until statisfied\n",
        "\n",
        "Since we've already beaten our baseline, there are a few things we could try to continue to improve our model:\n",
        "* Increas the number of model layers (e.g. add move Conv2D/MaxPool2D/layers)\n",
        "* Increase the number of filters in each convolutional layer(e.g. fom 10 to 32 or even 64)\n",
        "* Train for longer (epochs)\n",
        "* Find an ideal learning rate\n",
        "* Get more data (give the model more opporutnities to learn)\n",
        "* Use `transfer learning` to leverage what another image model has learn and adjust it for our own use case"
      ],
      "metadata": {
        "id": "sKcZY_MM7bV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a prediction with our trained model on our own custom data"
      ],
      "metadata": {
        "id": "pbCOKw4y6OjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes we're working with\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "aTh73nh-9Cdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View our example image\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n",
        "steak = mpimg.imread(\"03-steak.jpeg\")\n",
        "plt.imshow(steak)\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "iKT1YSi09KXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of our image\n",
        "steak.shape"
      ],
      "metadata": {
        "id": "ftJzLC-69s09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steak"
      ],
      "metadata": {
        "id": "Vf0QRcpnVVCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** When you train a neural network and you want to make a prediction with it on our own custom data, it's imortant that your custom data (or new data) is preprocessed into the same format as the data your model was train on."
      ],
      "metadata": {
        "id": "PfTtkQh4V-DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import and image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224): \n",
        "  \"\"\"Reads an image from filename, turns it itno a tensor and reshapes it to (img_shape, img_shape, color_channels).\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode the read file into a tensor\n",
        "  img = tf.image.decode_image(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, size=[img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img"
      ],
      "metadata": {
        "id": "_VcNPOg8WTsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in and preprocess our custom image\n",
        "steak = load_and_prep_image(\"03-steak.jpeg\")\n",
        "steak"
      ],
      "metadata": {
        "id": "VTn0zFYvVvc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_7.predict(tf.expand_dims(steak, axis=0))\n",
        "pred"
      ],
      "metadata": {
        "id": "8Dcm5amyVXjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our custom image is being put through our model, however, it currently outputs a prediction probability, wouldn't it be nice if we could visualize the image as well as the model's prediction?"
      ],
      "metadata": {
        "id": "yeh-jYqFdRDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of our class names\n",
        "class_names"
      ],
      "metadata": {
        "id": "9WU7tQ0bVijO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can index the predicted class by rounding the prediction probability and indexing it to class names\n",
        "pred_class = class_names[int(tf.round(pred))]\n",
        "pred_class"
      ],
      "metadata": {
        "id": "jZ0V7zV_dudj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model, filename, class_names=class_names):\n",
        "  \"\"\" \n",
        "  Imports an image located at filename, makes a prediction with model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediciton\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "Hne0nm6Cd_y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test our model on a custom image\n",
        "pred_and_plot(model_7, \"03-steak.jpeg\")"
      ],
      "metadata": {
        "id": "D83q9v73g7A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-class Image Classificaiton\n",
        "\n",
        "We've just been through a bunch of the following steps with a binary classification problem (pizza vs. steak), now we're going to step things up a notch with 10 classes fo food (multi-class classification).\n",
        "\n",
        "1. Become one with the data\n",
        "2. Preprocess the dtat (get it ready for a model)\n",
        "3. Create a model (start with a baseline)\n",
        "4. Fit the model (overfit it to make sure it works)\n",
        "5. Evaluate the model\n",
        "6. Adjust different hyperparameters and improve the model (try to beat baseline/reduce overfitting)\n",
        "7. Repeat until satisfied"
      ],
      "metadata": {
        "id": "blnESNpZhFXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import and become one with the data"
      ],
      "metadata": {
        "id": "QcGLxFUYh8Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import  zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "# unzip our data\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_all_data.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "nLjV7HoFjLSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through 10 classes of food image data\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'. \")\n"
      ],
      "metadata": {
        "id": "Ss_KLlCQkKE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la 10_food_classes_all_data/"
      ],
      "metadata": {
        "id": "CAl-GH7xkx1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the train and test directories\n",
        "train_dir = \"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_class_all_data/test/\""
      ],
      "metadata": {
        "id": "yCazrp9lk4ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "yuiBgqvAlN3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize, visualize, visualize\n",
        "import random\n",
        "img = view_random_image(target_dir=train_dir,\n",
        "                        target_class=random.choice(class_names))\n"
      ],
      "metadata": {
        "id": "7TxnRdklli9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(class_names)"
      ],
      "metadata": {
        "id": "k53Yjwd_l466"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess the data (prepare it for a mdoel)"
      ],
      "metadata": {
        "id": "BT5u8DV5l9Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescale \n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Load data in form directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             batch_size=32, \n",
        "                                             class_mode=\"categorical\")\n"
      ],
      "metadata": {
        "id": "a_1KuQzQmUTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a model (start with a baseline)\n",
        "\n",
        "We've been talking a lot abou the CNN explainer website... how about we just take their model (also on 10 classes) and use it for our problem...? "
      ],
      "metadata": {
        "id": "l8zCukzR0UAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation\n",
        "\n",
        "# Create our model (very similar to previous models but actually the same as CNNN explainer website)\n",
        "model_8 = Sequential([\n",
        "    Conv2D(10, 3, input_shape=(224, 224, 3)),\n",
        "    Activation(activation=\"relu\"),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10, activation=\"softmax\") # changed to have 10 out[ut neurons and use the softmax activation function\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "j_xKWZg14e2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Fit a model"
      ],
      "metadata": {
        "id": "2mUVA_Xs6dr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_8 = model_8.fit(train_data, # now 10 different classes\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "n_x1HdkQ61uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "FJMuzCwC7LCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3hHMOaV7Rcd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}